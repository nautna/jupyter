{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- check final regression example\n",
    "- query why dataset appears to be missing values, but in actuality is not (398 obs for some predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1\n",
    "\n",
    "In this first project you will create a framework to scope out data science projects. This framework will provide you with a guide to develop a well-articulated problem statement and analysis plan that will be robust and reproducible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and evaluate the following problem statement: \n",
    "Determine which free-tier customers will covert to paying customers, using demographic data collected at signup (age, gender, location, and profession) and customer useage data (days since last log in, and activity score `1 = active user`, `0 = inactive user`) based on Hooli data from Jan-Apr 2015. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. What is the outcome?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: predict/determine which customers will convert from free-tier to paying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. What are the predictors/covariates? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: age, gender, location, and profession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. What timeframe is this data relevant for?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Jan-Apr 2015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. What is the hypothesis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Customers with more favorable useage data (recent log in and/or activity score = 1) will more likely convert from the free-tier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get started with our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Create a data dictionary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: \n",
    "\n",
    "Variable | Description | Type of Variable\n",
    "---| ---| ---\n",
    "admit | 1 - admitted, 0 - not admitted | binary\n",
    "gpa | floating point indicating grade point average | continuous \n",
    "gre | integer indicating score on graduate exam | continuous\n",
    "prestige | provides prestige on scale of 1-4 for school | categorical \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/antuanweeks/DAT-NYC-37/projects/unit-projects/project-1/assets/admissions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "admit         int64\n",
       "gre         float64\n",
       "gpa         float64\n",
       "prestige    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes # checking the variable types in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>400.000000</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>398.00000</td>\n",
       "      <td>399.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.317500</td>\n",
       "      <td>588.040201</td>\n",
       "      <td>3.39093</td>\n",
       "      <td>2.486216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.466087</td>\n",
       "      <td>115.628513</td>\n",
       "      <td>0.38063</td>\n",
       "      <td>0.945333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>2.26000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>520.000000</td>\n",
       "      <td>3.13000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>580.000000</td>\n",
       "      <td>3.39500</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>660.000000</td>\n",
       "      <td>3.67000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            admit         gre        gpa    prestige\n",
       "count  400.000000  398.000000  398.00000  399.000000\n",
       "mean     0.317500  588.040201    3.39093    2.486216\n",
       "std      0.466087  115.628513    0.38063    0.945333\n",
       "min      0.000000  220.000000    2.26000    1.000000\n",
       "25%      0.000000  520.000000    3.13000    2.000000\n",
       "50%      0.000000  580.000000    3.39500    2.000000\n",
       "75%      1.000000  660.000000    3.67000    3.000000\n",
       "max      1.000000  800.000000    4.00000    4.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe() # we see there are 400 observations, but some rows are missing indpendent variable values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x117ba7b50>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x11840e390>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x1183c1490>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x118610a90>]], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.hist() # visualization of frequencies of variables within dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "null_data = df[df.isnull().any(axis=1)] # no values missing despite count from describe(). unsure cause of discrepancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     admit    gre   gpa  prestige\n",
      "0        0  380.0  3.61       3.0\n",
      "1        1  660.0  3.67       3.0\n",
      "2        1  800.0  4.00       1.0\n",
      "3        1  640.0  3.19       4.0\n",
      "4        0  520.0  2.93       4.0\n",
      "5        1  760.0  3.00       2.0\n",
      "6        1  560.0  2.98       1.0\n",
      "7        0  400.0  3.08       2.0\n",
      "8        1  540.0  3.39       3.0\n",
      "9        0  700.0  3.92       2.0\n",
      "10       0  800.0  4.00       4.0\n",
      "11       0  440.0  3.22       1.0\n",
      "12       1  760.0  4.00       1.0\n",
      "13       0  700.0  3.08       2.0\n",
      "14       1  700.0  4.00       1.0\n",
      "15       0  480.0  3.44       3.0\n",
      "16       0  780.0  3.87       4.0\n",
      "17       0  360.0  2.56       3.0\n",
      "18       0  800.0  3.75       2.0\n",
      "19       1  540.0  3.81       1.0\n",
      "20       0  500.0  3.17       3.0\n",
      "21       1  660.0  3.63       2.0\n",
      "22       0  600.0  2.82       4.0\n",
      "23       0  680.0  3.19       4.0\n",
      "24       1  760.0  3.35       2.0\n",
      "25       1  800.0  3.66       1.0\n",
      "26       1  620.0  3.61       1.0\n",
      "27       1  520.0  3.74       4.0\n",
      "28       1  780.0  3.22       2.0\n",
      "29       0  520.0  3.29       1.0\n",
      "30       0  540.0  3.78       4.0\n",
      "31       0  760.0  3.35       3.0\n",
      "32       0  600.0  3.40       3.0\n",
      "33       1  800.0  4.00       3.0\n",
      "34       0  360.0  3.14       1.0\n",
      "35       0  400.0  3.05       2.0\n",
      "36       0  580.0  3.25       1.0\n",
      "37       0  520.0  2.90       3.0\n",
      "38       1  500.0  3.13       2.0\n",
      "39       1  520.0  2.68       3.0\n",
      "40       0  560.0  2.42       2.0\n",
      "41       1  580.0  3.32       2.0\n",
      "42       1  600.0  3.15       2.0\n",
      "43       0  500.0  3.31       3.0\n",
      "44       0  700.0  2.94       2.0\n",
      "45       1  460.0  3.45       3.0\n",
      "46       1  580.0  3.46       2.0\n",
      "47       0  500.0  2.97       4.0\n",
      "48       0  440.0  2.48       4.0\n",
      "49       0  400.0  3.35       3.0\n",
      "50       0  640.0  3.86       3.0\n",
      "51       0  440.0  3.13       4.0\n",
      "52       0  740.0  3.37       4.0\n",
      "53       1  680.0  3.27       2.0\n",
      "54       0  660.0  3.34       3.0\n",
      "55       1  740.0  4.00       3.0\n",
      "56       0  560.0  3.19       3.0\n",
      "57       0  380.0  2.94       3.0\n",
      "58       0  400.0  3.65       2.0\n",
      "59       0  600.0  2.82       4.0\n",
      "60       1  620.0  3.18       2.0\n",
      "61       0  560.0  3.32       4.0\n",
      "62       0  640.0  3.67       3.0\n",
      "63       1  680.0  3.85       3.0\n",
      "64       0  580.0  4.00       3.0\n",
      "65       0  600.0  3.59       2.0\n",
      "66       0  740.0  3.62       4.0\n",
      "67       0  620.0  3.30       1.0\n",
      "68       0  580.0  3.69       1.0\n",
      "69       0  800.0  3.73       1.0\n",
      "70       0  640.0  4.00       3.0\n",
      "71       0  300.0  2.92       4.0\n",
      "72       0  480.0  3.39       4.0\n",
      "73       0  580.0  4.00       2.0\n",
      "74       0  720.0  3.45       4.0\n",
      "75       0  720.0  4.00       3.0\n",
      "76       0  560.0  3.36       3.0\n",
      "77       1  800.0  4.00       3.0\n",
      "78       0  540.0  3.12       1.0\n",
      "79       1  620.0  4.00       1.0\n",
      "80       0  700.0  2.90       4.0\n",
      "81       0  620.0  3.07       2.0\n",
      "82       0  500.0  2.71       2.0\n",
      "83       0  380.0  2.91       4.0\n",
      "84       1  500.0  3.60       3.0\n",
      "85       0  520.0  2.98       2.0\n",
      "86       0  600.0  3.32       2.0\n",
      "87       0  600.0  3.48       2.0\n",
      "88       0  700.0  3.28       1.0\n",
      "89       1  660.0  4.00       2.0\n",
      "90       0  700.0  3.83       2.0\n",
      "91       1  720.0  3.64       1.0\n",
      "92       0  800.0  3.90       2.0\n",
      "93       0  580.0  2.93       2.0\n",
      "94       1  660.0  3.44       2.0\n",
      "95       0  660.0  3.33       2.0\n",
      "96       0  640.0  3.52       4.0\n",
      "97       0  480.0  3.57       2.0\n",
      "98       0  700.0  2.88       2.0\n",
      "99       0  400.0  3.31       3.0\n",
      "100      0  340.0  3.15       3.0\n",
      "101      0  580.0  3.57       3.0\n",
      "102      0  380.0  3.33       4.0\n",
      "103      0  540.0  3.94       3.0\n",
      "104      1  660.0  3.95       2.0\n",
      "105      1  740.0  2.97       2.0\n",
      "106      1  700.0  3.56       1.0\n",
      "107      0  480.0  3.13       2.0\n",
      "108      0  400.0  2.93       3.0\n",
      "109      0  480.0  3.45       2.0\n",
      "110      0  680.0  3.08       4.0\n",
      "111      0  420.0  3.41       4.0\n",
      "112      0  360.0  3.00       3.0\n",
      "113      0  600.0  3.22       1.0\n",
      "114      0  720.0  3.84       3.0\n",
      "115      0  620.0  3.99       3.0\n",
      "116      1  440.0  3.45       2.0\n",
      "117      0  700.0  3.72       2.0\n",
      "118      1  800.0  3.70       1.0\n",
      "119      0  340.0  2.92       3.0\n",
      "120      1  520.0  3.74       2.0\n",
      "121      1  480.0  2.67       2.0\n",
      "122      0  520.0  2.85       3.0\n",
      "123      0  500.0  2.98       3.0\n",
      "124      0  720.0  3.88       3.0\n",
      "125      0  540.0  3.38       4.0\n",
      "126      1  600.0  3.54       1.0\n",
      "127      0  740.0  3.74       4.0\n",
      "128      0  540.0  3.19       2.0\n",
      "129      0  460.0  3.15       4.0\n",
      "130      1  620.0  3.17       2.0\n",
      "131      0  640.0  2.79       2.0\n",
      "132      0  580.0  3.40       2.0\n",
      "133      0  500.0  3.08       3.0\n",
      "134      0  560.0  2.95       2.0\n",
      "135      0  500.0  3.57       3.0\n",
      "136      0  560.0  3.33       4.0\n",
      "137      0  700.0  4.00       3.0\n",
      "138      0  620.0  3.40       2.0\n",
      "139      1  600.0  3.58       1.0\n",
      "140      0  640.0  3.93       2.0\n",
      "141      1  700.0  3.52       4.0\n",
      "142      0  620.0  3.94       4.0\n",
      "143      0  580.0  3.40       3.0\n",
      "144      0  580.0  3.40       4.0\n",
      "145      0  380.0  3.43       3.0\n",
      "146      0  480.0  3.40       2.0\n",
      "147      0  560.0  2.71       3.0\n",
      "148      1  480.0  2.91       1.0\n",
      "149      0  740.0  3.31       1.0\n",
      "150      1  800.0  3.74       1.0\n",
      "151      0  400.0  3.38       2.0\n",
      "152      1  640.0  3.94       2.0\n",
      "153      0  580.0  3.46       3.0\n",
      "154      0  620.0  3.69       3.0\n",
      "155      1  580.0  2.86       4.0\n",
      "156      0  560.0  2.52       2.0\n",
      "157      1  480.0  3.58       1.0\n",
      "158      0  660.0  3.49       2.0\n",
      "159      0  700.0  3.82       3.0\n",
      "160      0  600.0  3.13       2.0\n",
      "161      0  640.0  3.50       2.0\n",
      "162      1  700.0  3.56       2.0\n",
      "163      0  520.0  2.73       2.0\n",
      "164      0  580.0  3.30       2.0\n",
      "165      0  700.0  4.00       1.0\n",
      "166      0  440.0  3.24       4.0\n",
      "167      0  720.0  3.77       3.0\n",
      "168      0  500.0  4.00       3.0\n",
      "169      0  600.0  3.62       3.0\n",
      "170      0  400.0  3.51       3.0\n",
      "171      0  540.0  2.81       3.0\n",
      "172      0  680.0  3.48       3.0\n",
      "173      1  800.0  3.43       2.0\n",
      "174      0  500.0  3.53       4.0\n",
      "175      1  620.0  3.37       2.0\n",
      "176      0  520.0  2.62       2.0\n",
      "177      1  620.0  3.23       3.0\n",
      "178      0  620.0  3.33       3.0\n",
      "179      0  300.0  3.01       3.0\n",
      "180      0  620.0  3.78       3.0\n",
      "181      0  500.0  3.88       4.0\n",
      "182      0  700.0  4.00       2.0\n",
      "183      1  540.0  3.84       2.0\n",
      "184      0  500.0  2.79       4.0\n",
      "185      0  800.0  3.60       2.0\n",
      "186      0  560.0  3.61       3.0\n",
      "187      0    NaN   NaN       2.0\n",
      "188      0  560.0  3.07       2.0\n",
      "189      0  500.0  3.35       2.0\n",
      "190      1  640.0  2.94       2.0\n",
      "191      0  800.0  3.54       3.0\n",
      "192      0  640.0  3.76       3.0\n",
      "193      0  380.0  3.59       4.0\n",
      "194      1  600.0  3.47       2.0\n",
      "195      0  560.0  3.59       2.0\n",
      "196      0  660.0  3.07       3.0\n",
      "197      1  400.0  3.23       4.0\n",
      "198      0  600.0  3.63       3.0\n",
      "199      0  580.0  3.77       4.0\n",
      "200      0  800.0  3.31       3.0\n",
      "201      1  580.0  3.20       2.0\n",
      "202      1  700.0  4.00       1.0\n",
      "203      0  420.0  3.92       4.0\n",
      "204      1  600.0  3.89       1.0\n",
      "205      1  780.0  3.80       3.0\n",
      "206      0  740.0  3.54       1.0\n",
      "207      1  640.0  3.63       1.0\n",
      "208      0  540.0  3.16       3.0\n",
      "209      0  580.0  3.50       2.0\n",
      "210      0  740.0  3.34       4.0\n",
      "211      0  580.0  3.02       2.0\n",
      "212      0    NaN  2.87       2.0\n",
      "213      0  640.0  3.38       3.0\n",
      "214      1  600.0  3.56       2.0\n",
      "215      1  660.0  2.91       3.0\n",
      "216      0  340.0  2.90       1.0\n",
      "217      1  460.0  3.64       1.0\n",
      "218      0  460.0  2.98       1.0\n",
      "219      1  560.0  3.59       2.0\n",
      "220      0  540.0  3.28       3.0\n",
      "221      0  680.0  3.99       3.0\n",
      "222      1  480.0  3.02       1.0\n",
      "223      0  800.0  3.47       3.0\n",
      "224      0  800.0  2.90       2.0\n",
      "225      1  720.0  3.50       3.0\n",
      "226      0  620.0  3.58       2.0\n",
      "227      0  540.0  3.02       4.0\n",
      "228      0  480.0  3.43       2.0\n",
      "229      1  720.0  3.42       2.0\n",
      "230      0  580.0  3.29       4.0\n",
      "231      0  600.0  3.28       3.0\n",
      "232      0  380.0  3.38       2.0\n",
      "233      0  420.0  2.67       3.0\n",
      "234      1  800.0  3.53       1.0\n",
      "235      0  620.0  3.05       2.0\n",
      "236      1  660.0   NaN       NaN\n",
      "237      0  480.0  4.00       2.0\n",
      "238      0  500.0  2.86       4.0\n",
      "239      0  700.0  3.45       3.0\n",
      "240      0  440.0  2.76       2.0\n",
      "241      1  520.0  3.81       1.0\n",
      "242      1  680.0  2.96       3.0\n",
      "243      0  620.0  3.22       2.0\n",
      "244      0  540.0  3.04       1.0\n",
      "245      0  800.0  3.91       3.0\n",
      "246      0  680.0  3.34       2.0\n",
      "247      0  440.0  3.17       2.0\n",
      "248      0  680.0  3.64       3.0\n",
      "249      0  640.0  3.73       3.0\n",
      "250      0  660.0  3.31       4.0\n",
      "251      0  620.0  3.21       4.0\n",
      "252      1  520.0  4.00       2.0\n",
      "253      1  540.0  3.55       4.0\n",
      "254      1  740.0  3.52       4.0\n",
      "255      0  640.0  3.35       3.0\n",
      "256      1  520.0  3.30       2.0\n",
      "257      1  620.0  3.95       3.0\n",
      "258      0  520.0  3.51       2.0\n",
      "259      0  640.0  3.81       2.0\n",
      "260      0  680.0  3.11       2.0\n",
      "261      0  440.0  3.15       2.0\n",
      "262      1  520.0  3.19       3.0\n",
      "263      1  620.0  3.95       3.0\n",
      "264      1  520.0  3.90       3.0\n",
      "265      0  380.0  3.34       3.0\n",
      "266      0  560.0  3.24       4.0\n",
      "267      1  600.0  3.64       3.0\n",
      "268      1  680.0  3.46       2.0\n",
      "269      0  500.0  2.81       3.0\n",
      "270      1  640.0  3.95       2.0\n",
      "271      0  540.0  3.33       3.0\n",
      "272      1  680.0  3.67       2.0\n",
      "273      0  660.0  3.32       1.0\n",
      "274      0  520.0  3.12       2.0\n",
      "275      1  600.0  2.98       2.0\n",
      "276      0  460.0  3.77       3.0\n",
      "277      1  580.0  3.58       1.0\n",
      "278      1  680.0  3.00       4.0\n",
      "279      1  660.0  3.14       2.0\n",
      "280      0  660.0  3.94       2.0\n",
      "281      0  360.0  3.27       3.0\n",
      "282      0  660.0  3.45       4.0\n",
      "283      0  520.0  3.10       4.0\n",
      "284      1  440.0  3.39       2.0\n",
      "285      0  600.0  3.31       4.0\n",
      "286      1  800.0  3.22       1.0\n",
      "287      1  660.0  3.70       4.0\n",
      "288      0  800.0  3.15       4.0\n",
      "289      0  420.0  2.26       4.0\n",
      "290      1  620.0  3.45       2.0\n",
      "291      0  800.0  2.78       2.0\n",
      "292      0  680.0  3.70       2.0\n",
      "293      0  800.0  3.97       1.0\n",
      "294      0  480.0  2.55       1.0\n",
      "295      0  520.0  3.25       3.0\n",
      "296      0  560.0  3.16       1.0\n",
      "297      0  460.0  3.07       2.0\n",
      "298      0  540.0  3.50       2.0\n",
      "299      0  720.0  3.40       3.0\n",
      "300      0  640.0  3.30       2.0\n",
      "301      1  660.0  3.60       3.0\n",
      "302      1  400.0  3.15       2.0\n",
      "303      1  680.0  3.98       2.0\n",
      "304      0  220.0  2.83       3.0\n",
      "305      0  580.0  3.46       4.0\n",
      "306      1  540.0  3.17       1.0\n",
      "307      0  580.0  3.51       2.0\n",
      "308      0  540.0  3.13       2.0\n",
      "309      0  440.0  2.98       3.0\n",
      "310      0  560.0  4.00       3.0\n",
      "311      0  660.0  3.67       2.0\n",
      "312      0  660.0  3.77       3.0\n",
      "313      1  520.0  3.65       4.0\n",
      "314      0  540.0  3.46       4.0\n",
      "315      1  300.0  2.84       2.0\n",
      "316      1  340.0  3.00       2.0\n",
      "317      1  780.0  3.63       4.0\n",
      "318      1  480.0  3.71       4.0\n",
      "319      0  540.0  3.28       1.0\n",
      "320      0  460.0  3.14       3.0\n",
      "321      0  460.0  3.58       2.0\n",
      "322      0  500.0  3.01       4.0\n",
      "323      0  420.0  2.69       2.0\n",
      "324      0  520.0  2.70       3.0\n",
      "325      0  680.0  3.90       1.0\n",
      "326      0  680.0  3.31       2.0\n",
      "327      1  560.0  3.48       2.0\n",
      "328      0  580.0  3.34       2.0\n",
      "329      0  500.0  2.93       4.0\n",
      "330      0  740.0  4.00       3.0\n",
      "331      0  660.0  3.59       3.0\n",
      "332      0  420.0  2.96       1.0\n",
      "333      0  560.0  3.43       3.0\n",
      "334      1  460.0  3.64       3.0\n",
      "335      1  620.0  3.71       1.0\n",
      "336      0  520.0  3.15       3.0\n",
      "337      0  620.0  3.09       4.0\n",
      "338      0  540.0  3.20       1.0\n",
      "339      1  660.0  3.47       3.0\n",
      "340      0  500.0  3.23       4.0\n",
      "341      1  560.0  2.65       3.0\n",
      "342      0  500.0  3.95       4.0\n",
      "343      0  580.0  3.06       2.0\n",
      "344      0  520.0  3.35       3.0\n",
      "345      0  500.0  3.03       3.0\n",
      "346      0  600.0  3.35       2.0\n",
      "347      0  580.0  3.80       2.0\n",
      "348      0  400.0  3.36       2.0\n",
      "349      0  620.0  2.85       2.0\n",
      "350      1  780.0  4.00       2.0\n",
      "351      0  620.0  3.43       3.0\n",
      "352      1  580.0  3.12       3.0\n",
      "353      0  700.0  3.52       2.0\n",
      "354      1  540.0  3.78       2.0\n",
      "355      1  760.0  2.81       1.0\n",
      "356      0  700.0  3.27       2.0\n",
      "357      0  720.0  3.31       1.0\n",
      "358      1  560.0  3.69       3.0\n",
      "359      0  720.0  3.94       3.0\n",
      "360      1  520.0  4.00       1.0\n",
      "361      1  540.0  3.49       1.0\n",
      "362      0  680.0  3.14       2.0\n",
      "363      0  460.0  3.44       2.0\n",
      "364      1  560.0  3.36       1.0\n",
      "365      0  480.0  2.78       3.0\n",
      "366      0  460.0  2.93       3.0\n",
      "367      0  620.0  3.63       3.0\n",
      "368      0  580.0  4.00       1.0\n",
      "369      0  800.0  3.89       2.0\n",
      "370      1  540.0  3.77       2.0\n",
      "371      1  680.0  3.76       3.0\n",
      "372      1  680.0  2.42       1.0\n",
      "373      1  620.0  3.37       1.0\n",
      "374      0  560.0  3.78       2.0\n",
      "375      0  560.0  3.49       4.0\n",
      "376      0  620.0  3.63       2.0\n",
      "377      1  800.0  4.00       2.0\n",
      "378      0  640.0  3.12       3.0\n",
      "379      0  540.0  2.70       2.0\n",
      "380      0  700.0  3.65       2.0\n",
      "381      1  540.0  3.49       2.0\n",
      "382      0  540.0  3.51       2.0\n",
      "383      0  660.0  4.00       1.0\n",
      "384      1  480.0  2.62       2.0\n",
      "385      0  420.0  3.02       1.0\n",
      "386      1  740.0  3.86       2.0\n",
      "387      0  580.0  3.36       2.0\n",
      "388      0  640.0  3.17       2.0\n",
      "389      0  640.0  3.51       2.0\n",
      "390      1  800.0  3.05       2.0\n",
      "391      1  660.0  3.88       2.0\n",
      "392      1  600.0  3.38       3.0\n",
      "393      1  620.0  3.75       2.0\n",
      "394      1  460.0  3.99       3.0\n",
      "395      0  620.0  4.00       2.0\n",
      "396      0  560.0  3.04       3.0\n",
      "397      0  460.0  2.63       2.0\n",
      "398      0  700.0  3.65       2.0\n",
      "399      0  600.0  3.89       3.0\n"
     ]
    }
   ],
   "source": [
    "with pd.option_context('display.max_rows', 999, 'display.max_columns', 5): # manually viewing yields no missing data\n",
    "    print df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x118610a90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gre_count = df['gre'].value_counts() #showing distribution of gre scores\n",
    "\n",
    "gre_count.head(10).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is the impact of GRE score on admission (see graph below)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df800 = df[df['gre'] > 700]['admit'] # computing the counts for admission based on score range \n",
    "df700 = df[(df['gre'] > 600) & (df['gre'] <= 700)]['admit']\n",
    "df600 = df[(df['gre'] > 500) & (df['gre'] <= 600)]['admit']\n",
    "df500 = df[(df['gre'] > 400) & (df['gre'] <= 500)]['admit']\n",
    "df800_1 = df[(df['gre'] > 700) & (df['admit'] == 1)]['admit'].count()\n",
    "df700_1 = df[(df['gre'] > 600) & (df['gre'] <= 700) & (df['admit'] == 1)]['admit'].count()\n",
    "df600_1 = df[(df['gre'] > 500) & (df['gre'] <= 600) & (df['admit'] == 1)]['admit'].count()\n",
    "df500_1 = df[(df['gre'] > 400) & (df['gre'] <= 500) & (df['admit'] == 1)]['admit'].count()\n",
    "df800_0 = df[(df['gre'] > 700) & (df['admit'] == 0)]['admit'].count()\n",
    "df700_0 = df[(df['gre'] > 600) & (df['gre'] <= 700) & (df['admit'] == 0)]['admit'].count()\n",
    "df600_0 = df[(df['gre'] > 500) & (df['gre'] <= 600) & (df['admit'] == 0)]['admit'].count()\n",
    "df500_0 = df[(df['gre'] > 400) & (df['gre'] <= 500) & (df['admit'] == 0)]['admit'].count()\n",
    "df800_std = df800.std()\n",
    "df700_std = df700.std()\n",
    "df600_std = df600.std()\n",
    "df500_std = df500.std()\n",
    "agg_admit = [df500_1, df600_1, df700_1, df800_1]\n",
    "agg_nonadmit = [df500_0, df600_0, df700_0, df800_0]\n",
    "agg_std = [df800_std, df700_std, df600_std, df500_std]\n",
    "loc = np.arange(4)\n",
    "width = 0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph below shows that a smaller proprotion of students applying with lower GRE score ranges are admitted compared to the number of students applying within that score range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x102632090>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot1 = plt.bar(loc, agg_admit, width, color='b')\n",
    "plot2 = plt.bar(loc, agg_nonadmit, width, color='r', bottom=agg_admit)\n",
    "plt.ylabel('Number of Applicants')\n",
    "plt.title('Admission by GRE Score Range')\n",
    "plt.xticks(loc + width/2., ('401-500', '501-600', '601-700', '701-800'))\n",
    "plt.legend((plot1[0], plot2[0]), ('Admitted', 'Not Admitted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to explore the association between 'admit' and 'gpa,' 'gre,' and 'prestige.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. What is the outcome?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: determine probability of admission based on underlying characteristics/determinants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. What are the predictors/covariates? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: 'gpa,' 'gre,' and 'prestige' are the predictors/covariates, as these variables are used in the admissions process to determine whether or not an applicant will be admitted "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. What timeframe is this data relevant for?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: there is no explicit timeframe given with the dataset (we assume one application cycle). The generated data is hypothetical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. What is the hypothesis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: No single predictor alone will predict graduate school admission. Admission will inversely vary with decreasing undergraduate college prestige and have a positive correlation with gpa and gre, allowing for greater likelihood of admission for students with good scores from prestigious schools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Using the above information, write a well-formed problem statement. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    "Discern the correlation between UCLA graduate applicant characteristics and admission. Using an admissions dataset published by UCLA, I will test for the drivers of graduate school admission. The data is hypothetical and generated for the purposes of providing an example for R Data analysis using Logit Regression. The dataset includes four variables ('admit,' 'gre,' 'gpa,' and 'prestige') in which 'admit' is the dependent variable and 'gre,' 'gpa,' and 'prestige' are predictor variables. I believe no single predictor alone can sufficiently predict graduate school admision. My hypothesis is that admission will vary inversely with decreasing undergraduate college prestige and have a positive correlation with gpa and gre, allowing for greater likelihood of admission for students with good scores from prestigious schools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Analysis Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the lab from a class as a guide, create an exploratory analysis plan. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. What are the goals of the exploratory analysis? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Answer: One goal of the exploratory analysis is to become familiar with the dataset: its variables and the completeness of the dataset. It is important to understand what the variable values represent (e.g. is a prestige score of 1 good or bad) so that interpretations from analysis are accurate. It is also important to determine the completeness of the dataset in order to gauge how much confidence you can place in some of your findings. If half of the observations are null, or there are few observations in the first place, it will be challenging/not possible to establish causal links or correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2a. What are the assumptions of the distribution of data? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: There will be multiple distribution types since the variable type varies. Poisson binomial distribution for the binary 'admit' variable, and normal distributions for the continuous and categorical variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2b. How will you determine the distribution of your data? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Answer: We can plot the frequencies of each variable using .hist() to see the distribution of each variable (see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x1188f18d0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x1189af910>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x118965dd0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x118b94e50>]], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3a. How might outliers impact your analysis? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Answer: The data does not appear to be skewed much by outliers. Removal of any outliers might actually impact the efficacy of a predictive model. The box plots below provide some insight into why we may not remove outliers in our analyses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x118b94e50>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.boxplot('gre', return_type='axes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x118b94e50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.boxplot('gpa', return_type='axes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x118b94e50>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.boxplot('prestige', return_type='axes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3b. How will you test for outliers? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: We can test for outliers using standard deviation testing. If a value is more than 3 standard deviations from the mean, we can choose to omit the value (see below). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>2.83</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     admit    gre   gpa  prestige\n",
       "304      0  220.0  2.83       3.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[np.abs(df.gre-df.gre.mean())>=(3*df.gre.std())] # this value is the only outlier with this method (I tested other \n",
    "# variables as well). Below I will test if removing the value has any significant effect. If not, we will keep the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2 = df[np.abs(df.gre-df.gre.mean())<=(3*df.gre.std())] # setting new data frame w/out outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>admit</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.182919</td>\n",
       "      <td>0.175952</td>\n",
       "      <td>-0.241355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gre</th>\n",
       "      <td>0.182919</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.382408</td>\n",
       "      <td>-0.124533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpa</th>\n",
       "      <td>0.175952</td>\n",
       "      <td>0.382408</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.059031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prestige</th>\n",
       "      <td>-0.241355</td>\n",
       "      <td>-0.124533</td>\n",
       "      <td>-0.059031</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             admit       gre       gpa  prestige\n",
       "admit     1.000000  0.182919  0.175952 -0.241355\n",
       "gre       0.182919  1.000000  0.382408 -0.124533\n",
       "gpa       0.175952  0.382408  1.000000 -0.059031\n",
       "prestige -0.241355 -0.124533 -0.059031  1.000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr() # original dataframe correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>admit</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.179844</td>\n",
       "      <td>0.172145</td>\n",
       "      <td>-0.242864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gre</th>\n",
       "      <td>0.179844</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.376383</td>\n",
       "      <td>-0.121800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpa</th>\n",
       "      <td>0.172145</td>\n",
       "      <td>0.376383</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.059141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prestige</th>\n",
       "      <td>-0.242864</td>\n",
       "      <td>-0.121800</td>\n",
       "      <td>-0.059141</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             admit       gre       gpa  prestige\n",
       "admit     1.000000  0.179844  0.172145 -0.242864\n",
       "gre       0.179844  1.000000  0.376383 -0.121800\n",
       "gpa       0.172145  0.376383  1.000000 -0.059141\n",
       "prestige -0.242864 -0.121800 -0.059141  1.000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.corr() # correlation matrix with outlier removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the above tests show that there is no significant effect from removing the outlier. df represents the original dataset, while df2 represents the dataset with outlier removed. Note magnitudes are similar and all signs are the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4a. What is collinearity? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Answer: Collinearity occurs when two or more predictor variables are highly correlated, leading to predictability of the variables based on the presence or occurrence of the other. This is an issue in regression, because it is hard to discern what is the ultimate cause or reason for a dependent change if multiple features in the analysis are contributing to the change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4b. How will you test for collinearity? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: The above tests provide a matrix of correlation coefficients for the variables in the database. From first glance, there appear to be collinearity between the 'gre' and 'gpa' variables. We can attempt to isolate one of the variables by running the model without the other in order to tease out the effect of an individual variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. What is your exploratory analysis plan?\n",
    "Using the above information, write an exploratory analysis plan that would allow you or a colleague to reproduce your analysis one year from now. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: To begin, we will become familiar with the dataset. To do this, we will plot variable frequency tables to see the data distributions, and test for outliers within the dataset. If we find that the dataset includes outliers that significantly impact the analysis, we will drop the outliers. We will test for outliers by removing any values that are more than three standard deviations away from the mean. Following our test for outliers, we will test for multicollinearity by genearating a correlation matrix. If we find that any of the predictor variables are highly correlated, we will attempt to discern the true impact by dropping one or more of the potential candidates for multicollinearity. This will allow us to more accurately tease out the effects of individual predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Questions:\n",
    "1. Outline your analysis method for predicting your outcome\n",
    "2. Write an alternative problem statement for your dataset\n",
    "3. Articulate the assumptions and risks of the alternative model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Analysis Method Outline\n",
    "\n",
    "To predict an outcome, we will use logistic regression. This will allow us to discern the causal effects of each predictor variable upon our dependent variable. Below are the steps to prepare and analyze the dataset:\n",
    "- acquire dataset\n",
    "- explore dataset in order to understand variables\n",
    "- modify datset in preparation for logistic regresion (linear regression has continuous dependent variable; logistic has a limited number of outcomes. since our dataset dependent variable is binary, logistic fits well)\n",
    "    - create dummy variables for categorical 'pretige' variable\n",
    "    - determine if any variables are effected by multicollinearity; if so determine if variables will be analyzed separately\n",
    "- from regression results, determine if results are significant\n",
    "- interpret and summarize results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Alternative Problem Statement\n",
    "Discern the pretige of a UCLA graduate school applicant's undergraduate school. Using an admissions dataset published by UCLA, I will test to see if the prestige of an applicant's undergraduate college is inferable from other variables within the dataset. The data is hypothetical and generated for the purposes of providing an example for R Data analysis using Logit Regression. The dataset includes four variables ('admit,' 'gre,' 'gpa,' and 'prestige') in which 'prestige' is the dependent variable and 'gre,' 'gpa,' and 'admit' are predictor variables. My hypothesis is that there will be a positive correlation between prestige and the various predictor variables, and that GRE score will contribute most to the predictive model--a higher GRE score coupled with the other variables being favorable will imply an applicant from a more prestigious undergraduate school."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Assumptions and Risks of Alternative Model\n",
    "We will assume that the continuous variables are distributed normally. If the dataset is not a random sampling, there might be biases introduced into our interpretations and analysis. We must test for multicollinearity to make sure that we are determining the true effect of predictor variables and not conflating the impact of a particular set of variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummy_prestige = pd.get_dummies(df['prestige'], prefix='prestige', drop_first=True) # dummies with k-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prestige_2.0</th>\n",
       "      <th>prestige_3.0</th>\n",
       "      <th>prestige_4.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prestige_2.0  prestige_3.0  prestige_4.0\n",
       "0           0.0           1.0           0.0\n",
       "1           0.0           1.0           0.0\n",
       "2           0.0           0.0           0.0\n",
       "3           0.0           0.0           1.0\n",
       "4           0.0           0.0           1.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_prestige.head() # view dummy DataFrame to make sure we have what we expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kept_columns = ['admit', 'gre', 'gpa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3 = df[kept_columns].join(dummy_prestige.ix[:, :]) # help from yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige_2.0</th>\n",
       "      <th>prestige_3.0</th>\n",
       "      <th>prestige_4.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>3.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>2.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit    gre   gpa  prestige_2.0  prestige_3.0  prestige_4.0\n",
       "0      0  380.0  3.61           0.0           1.0           0.0\n",
       "1      1  660.0  3.67           0.0           1.0           0.0\n",
       "2      1  800.0  4.00           0.0           0.0           0.0\n",
       "3      1  640.0  3.19           0.0           0.0           1.0\n",
       "4      0  520.0  2.93           0.0           0.0           1.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head() # viewing the new dataframe to make sure the data is in correct form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictors = df3.columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige_2.0</th>\n",
       "      <th>prestige_3.0</th>\n",
       "      <th>prestige_4.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>380.0</td>\n",
       "      <td>3.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>660.0</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>800.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>640.0</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>520.0</td>\n",
       "      <td>2.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     gre   gpa  prestige_2.0  prestige_3.0  prestige_4.0\n",
       "0  380.0  3.61           0.0           1.0           0.0\n",
       "1  660.0  3.67           0.0           1.0           0.0\n",
       "2  800.0  4.00           0.0           0.0           0.0\n",
       "3  640.0  3.19           0.0           0.0           1.0\n",
       "4  520.0  2.93           0.0           0.0           1.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3[predictors].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige_2.0</th>\n",
       "      <th>prestige_3.0</th>\n",
       "      <th>prestige_4.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>400.000000</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>398.00000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.317500</td>\n",
       "      <td>588.040201</td>\n",
       "      <td>3.39093</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.302500</td>\n",
       "      <td>0.167500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.466087</td>\n",
       "      <td>115.628513</td>\n",
       "      <td>0.38063</td>\n",
       "      <td>0.484729</td>\n",
       "      <td>0.459916</td>\n",
       "      <td>0.373889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>2.26000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>520.000000</td>\n",
       "      <td>3.13000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>580.000000</td>\n",
       "      <td>3.39500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>660.000000</td>\n",
       "      <td>3.67000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            admit         gre        gpa  prestige_2.0  prestige_3.0  \\\n",
       "count  400.000000  398.000000  398.00000    400.000000    400.000000   \n",
       "mean     0.317500  588.040201    3.39093      0.375000      0.302500   \n",
       "std      0.466087  115.628513    0.38063      0.484729      0.459916   \n",
       "min      0.000000  220.000000    2.26000      0.000000      0.000000   \n",
       "25%      0.000000  520.000000    3.13000      0.000000      0.000000   \n",
       "50%      0.000000  580.000000    3.39500      0.000000      0.000000   \n",
       "75%      1.000000  660.000000    3.67000      1.000000      1.000000   \n",
       "max      1.000000  800.000000    4.00000      1.000000      1.000000   \n",
       "\n",
       "       prestige_4.0  \n",
       "count    400.000000  \n",
       "mean       0.167500  \n",
       "std        0.373889  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "On entry to DLASCL parameter number 5 had an illegal value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-e1121940c53f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlogit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'admit'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# unsure why this returns an error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/antuanweeks/anaconda/lib/python2.7/site-packages/statsmodels/discrete/discrete_model.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBinaryModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m         if (self.__class__.__name__ != 'MNLogit' and\n\u001b[1;32m    403\u001b[0m                 not np.all((self.endog >= 0) & (self.endog <= 1))):\n",
      "\u001b[0;32m/Users/antuanweeks/anaconda/lib/python2.7/site-packages/statsmodels/discrete/discrete_model.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \"\"\"\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDiscreteModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_on_perfect_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/antuanweeks/anaconda/lib/python2.7/site-packages/statsmodels/base/model.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLikelihoodModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/antuanweeks/anaconda/lib/python2.7/site-packages/statsmodels/base/model.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mhasconst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hasconst'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         self.data = self._handle_data(endog, exog, missing, hasconst,\n\u001b[0;32m---> 60\u001b[0;31m                                       **kwargs)\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_constant\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_constant\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexog\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/antuanweeks/anaconda/lib/python2.7/site-packages/statsmodels/base/model.pyc\u001b[0m in \u001b[0;36m_handle_data\u001b[0;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_handle_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhasconst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhasconst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0;31m# kwargs arrays could have changed, easier to just attach here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/antuanweeks/anaconda/lib/python2.7/site-packages/statsmodels/base/data.pyc\u001b[0m in \u001b[0;36mhandle_data\u001b[0;34m(endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle_data_class_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m     return klass(endog, exog=exog, missing=missing, hasconst=hasconst,\n\u001b[0;32m--> 566\u001b[0;31m                  **kwargs)\n\u001b[0m",
      "\u001b[0;32m/Users/antuanweeks/anaconda/lib/python2.7/site-packages/statsmodels/base/data.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;31m# this has side-effects, attaches k_constant and const_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_constant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhasconst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_integrity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresettable_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/antuanweeks/anaconda/lib/python2.7/site-packages/statsmodels/base/data.pyc\u001b[0m in \u001b[0;36m_handle_constant\u001b[0;34m(self, hasconst)\u001b[0m\n\u001b[1;32m    132\u001b[0m                 augmented_exog = np.column_stack(\n\u001b[1;32m    133\u001b[0m                             (np.ones(self.exog.shape[0]), self.exog))\n\u001b[0;32m--> 134\u001b[0;31m                 \u001b[0mrank_augm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp_matrix_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maugmented_exog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m                 \u001b[0mrank_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp_matrix_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_constant\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrank_orig\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mrank_augm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/antuanweeks/anaconda/lib/python2.7/site-packages/numpy/linalg/linalg.pyc\u001b[0m in \u001b[0;36mmatrix_rank\u001b[0;34m(M, tol)\u001b[0m\n\u001b[1;32m   1541\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1542\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1543\u001b[0;31m     \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_uv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1544\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtol\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1545\u001b[0m         \u001b[0mtol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/antuanweeks/anaconda/lib/python2.7/site-packages/numpy/linalg/linalg.pyc\u001b[0m in \u001b[0;36msvd\u001b[0;34m(a, full_matrices, compute_uv)\u001b[0m\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m         \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->d'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->d'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1371\u001b[0;31m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1372\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_realType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: On entry to DLASCL parameter number 5 had an illegal value"
     ]
    }
   ],
   "source": [
    "logit = sm.Logit(df3['admit'], df3[predictors]) # unsure why this returns an error\n",
    "result = logit.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
